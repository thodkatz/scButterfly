import random
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset
from matplotlib.backends.backend_pdf import PdfPages
import matplotlib.pyplot as plt
from scipy import sparse
import anndata as ad
import pandas as pd
import gc
import scanpy as sc
from scipy import stats


class RNA_ATAC_dataset(Dataset):
    def __init__(self, R_data, A_data, id_list_r, id_list_a):
        """
        Set random seed.

        Parameters
        ----------
        R_data
            complete RNA data for model traning and testing.
            
        A_data
            complete ATAC data for model traning and testing.

        id_list_r
            ids of cells in RNA data used for model training.
            
        id_list_a
            ids of cells in ATAC data used for model training.    
        
        """
        
        self.RNA_dataset = R_data        
        self.ATAC_dataset = A_data
        self.id_list_r = id_list_r
        self.id_list_a = id_list_a
        self.r_count = len(self.id_list_r)
        self.a_count = len(self.id_list_a)

    def __len__(self):
        return self.r_count

    def __getitem__(self, idx):
        RNA_x = self.RNA_dataset[self.id_list_r[idx], :]
        ATAC_x = self.ATAC_dataset[self.id_list_a[idx], :]
        RNA_x = torch.from_numpy(RNA_x)
        ATAC_x = torch.from_numpy(ATAC_x)
        sample = torch.cat([RNA_x, ATAC_x])
        return sample


class Single_omics_dataset(Dataset):
    def __init__(self, data, id_list):
        """
        Set random seed.

        Parameters
        ----------
        data
            complete data for model traning and testing.

        id_list
            id of cells used for model training.
        
        """

        self.dataset = data        
        self.id_list = id_list

    def __len__(self):
        return len(self.id_list)

    def __getitem__(self, idx):
        x = self.dataset[self.id_list[idx], :]
        x = torch.from_numpy(x)
        return x   


def setup_seed(seed):
    """
    Set random seed.
    
    Parameters
    ----------
    seed
        Number to be set as random seed for reproducibility.
        
    """
    np.random.seed(seed)
    random.seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.manual_seed(seed)


class EarlyStopping:
    """Cite from https://github.com/Bjarten/early-stopping-pytorch"""
    """Early stops the training if validation loss doesn't improve after a given patience."""
    def __init__(self, patience=7, verbose=False, delta=0):
        """
        Args:
            patience (int): How long to wait after last time validation loss improved.
                            Default: 7
            verbose (bool): If True, prints a message for each validation loss improvement. 
                            Default: False
            delta (float): Minimum change in the monitored quantity to qualify as an improvement.
                            Default: 0
        """
        self.patience = patience
        self.verbose = verbose
        self.counter = 0
        self.best_score = None
        self.early_stop = False
        self.val_loss_min = np.Inf
        self.delta = delta

    def __call__(self, val_loss, model, path):

        score = -val_loss

        if self.best_score is None:
            self.best_score = score
            self.save_checkpoint(val_loss, model, path)
        elif score < self.best_score + self.delta:
            self.counter += 1
            # print(f'EarlyStopping counter: {self.counter} out of {self.patience}')
            if self.counter >= self.patience:
                self.early_stop = True
        else:
            self.best_score = score
            self.save_checkpoint(val_loss, model, path)
            self.counter = 0

    def save_checkpoint(self, val_loss, model, path):
        '''Saves model when validation loss decrease.'''
        if self.verbose:
            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')
        model.save_model_dict(path) # save best model here
        self.val_loss_min = val_loss

        
def tensor2adata(x, var, obs, val=1e-4):
    """
    Transform the tensor list to an Anndata.
    
    Parameters
    ----------
    x
        tensor list to concatenate.

    val
        value for sparse for matrix, default 1e-4.
        
    Returns
    ----------
    x
        concatenated anndata.
        
    """
    x = torch.cat(x)
    x = torch.masked_fill(x, x < val, 0)
    x = sparse.csr_matrix(x)
    x = ad.AnnData(x)
    x.obs = obs
    x.var = var
    return x


def tensor2adata_adt(x):
    """
    Transform the tensor list to an Anndata.
    
    Parameters
    ----------
    x
        tensor list to concatenate.

    Returns
    ----------
    x
        concatenated anndata.
        
    """
    x = torch.cat(x)
    x = sparse.csr_matrix(x)
    x = ad.AnnData(x)
    return x


def record_loss_log(
    pretrain_r_loss,
    pretrain_r_kl,
    pretrain_r_loss_val,
    pretrain_r_kl_val,
    pretrain_a_loss,
    pretrain_a_kl,
    pretrain_a_loss_val,
    pretrain_a_kl_val,
    train_loss,
    train_kl,
    train_discriminator,
    train_loss_val,
    train_kl_val,
    train_discriminator_val,
    path
):
    """
    Record run loss of training.
    
    Parameters
    ----------
    pretrain_r_loss
        train reconstruct loss of pretrain for RNA.
        
    pretrain_r_kl
        train kl divergence of pretrain for RNA.
        
    pretrain_r_loss_val
        validation reconstruct loss of pretrain for RNA.
        
    pretrain_r_kl_val
        validation kl divergence of pretrain for RNA.
        
    pretrain_a_loss
        train reconstruct loss of pretrain for ATAC.
        
    pretrain_a_kl
        train kl divergence of pretrain for ATAC.
        
    pretrain_a_loss_val
        validation reconstruct loss of pretrain for ATAC.
        
    pretrain_a_kl_val
        validation kl divergence of pretrain for ATAC.
        
    train_loss
        train reconstruct loss of train.
        
    train_kl
        train kl divergence of train.
        
    train_discriminator
        validation reconstruct loss of train.
        
    train_loss_val
        train reconstruct loss of train.
        
    train_kl_val
        train kl divergence of train.
        
    train_discriminator_val
        validation reconstruct train.
   
    path
        path for saving runlog.
    
    """
    fig_pretrain_r = plt.figure()
    ax_pretrain_r_re = fig_pretrain_r.add_subplot(1, 2, 1)
    ax_pretrain_r_kl = fig_pretrain_r.add_subplot(1, 2, 2)
    
    ax_pretrain_r_re.plot(pretrain_r_loss)
    ax_pretrain_r_re.plot(pretrain_r_loss_val)
    ax_pretrain_r_re.set_title('Reconstruct Loss for RNA Pretrain')
    
    ax_pretrain_r_kl.plot(pretrain_r_kl)
    ax_pretrain_r_kl.plot(pretrain_r_kl_val)
    ax_pretrain_r_kl.set_title('KL Divergence for RNA Pretrain')
    fig_pretrain_r.tight_layout()
    
    fig_pretrain_a = plt.figure()   
    ax_pretrain_a_re = fig_pretrain_a.add_subplot(1, 2, 1)
    ax_pretrain_a_kl = fig_pretrain_a.add_subplot(1, 2, 2)
    
    ax_pretrain_a_re.plot(pretrain_a_loss)
    ax_pretrain_a_re.plot(pretrain_a_loss_val)
    ax_pretrain_a_re.set_title('Reconstruct Loss for ATAC Pretrain')
    
    ax_pretrain_a_kl.plot(pretrain_a_kl)
    ax_pretrain_a_kl.plot(pretrain_a_kl_val)
    ax_pretrain_a_kl.set_title('KL Divergence for ATAC Pretrain')
    fig_pretrain_a.tight_layout()
    
    fig_train = plt.figure()
    ax_train_re = fig_train.add_subplot(1, 3, 1)
    ax_train_kl = fig_train.add_subplot(1, 3, 2)
    ax_train_dis = fig_train.add_subplot(1, 3, 3)
    
    ax_train_re.plot(train_loss)
    ax_train_re.plot(train_loss_val)
    ax_train_re.set_title('Reconstruct Loss for Train')
    
    ax_train_kl.plot(train_kl)
    ax_train_kl.plot(train_kl_val)
    ax_train_kl.set_title('KL Divergence for Train')
    
    ax_train_dis.plot(train_discriminator)
    ax_train_dis.plot(train_discriminator_val)
    ax_train_dis.set_title('Discriminator Loss for Train')
    fig_train.tight_layout()
    
    fig_list = [fig_pretrain_r, fig_pretrain_a, fig_train]
    with PdfPages(path + '/run_log.pdf') as pdf:
        for i in range(len(fig_list)):
            pdf.savefig(figure=fig_list[i], dpi=200)
            plt.close()
            

def idx2adata_multiVI(
    adata,
    train_id,
    validation_id, 
    test_id
):
    """
    Split datasets into train, validation and test part using cell id.
    
    Parameters
    ----------
    RNA_data
        full RNA data for spliting.
        
    ATAC_data
        full ATAC data for spliting.
        
    train_id
        cell index list used for model training.
   
    validation_id
        cell index list used for model validation.
        
    test_id
        cell index list used for model testing.
        
    """
    #train_id.extend(validation_id)
    train_adata = ad.AnnData(adata.X[train_id, :])
    test_adata = ad.AnnData(adata.X[test_id, :])

    train_adata.var = adata.var
    test_adata.var = adata.var

    train_adata.obs = adata.obs.iloc[train_id, :].copy()
    test_adata.obs = adata.obs.iloc[test_id, :].copy()

    train_adata.obs.reset_index(drop=True, inplace=True)
    test_adata.obs.reset_index(drop=True, inplace=True)

    return train_adata, test_adata

def get_pearson2(eval_adata, key_dic, n_degs=100, sample_ratio=0.8, times=100):
    """
    """
    stim_key = key_dic['stim_key']
    pred_key = key_dic['pred_key']
    ctrl_key = key_dic['ctrl_key']
    condition_key = key_dic['condition_key']
    sc.tl.rank_genes_groups(eval_adata, groupby=condition_key, reference=ctrl_key, method="wilcoxon")
    degs = eval_adata.uns["rank_genes_groups"]["names"][stim_key][:n_degs]
    df_stim = eval_adata[(eval_adata.obs[condition_key] == stim_key)].to_df()
    df_pred = eval_adata[(eval_adata.obs[condition_key] == pred_key)].to_df()
    data = np.zeros((times, 1))
    for i in range(times):
        stim = df_stim.sample(frac=sample_ratio, random_state=i)
        pred = df_pred.sample(frac=sample_ratio, random_state=i)

        stim_degs_mean = stim.loc[:, degs].mean().values.reshape(1, -1)
        pred_degs_mean = pred.loc[:, degs].mean().values.reshape(1, -1)

        r2_degs_mean = (np.corrcoef(stim_degs_mean, pred_degs_mean)[0, 1]) ** 2
    

        data[i, 0] = r2_degs_mean
    df = pd.DataFrame(data, columns=['r2_degs_mean'])
    return df